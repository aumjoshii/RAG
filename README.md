# Ragline â€” Local RAG System (Free, Offline)

A fully functional Retrieval-Augmented Generation (RAG) app that runs locally with:
- **.NET API** (upload, index, ask)
- **Local embeddings** via a Python FastAPI microservice (Sentence-Transformers)
- **Local LLM** via Ollama
- **SQLite persistence** (restart-safe)
- Simple UI to upload files, ask questions, and view sources

## Features
- Upload **.txt** (and optionally .pdf if enabled) and index into a vector store (SQLite)
- Ask questions and get:
  - Answer generated by a local LLM (Ollama)
  - Top-k supporting source chunks with similarity scores
- List indexed documents in UI

## Tech Stack
- Backend: **.NET 8 Minimal API**
- Embeddings: **sentence-transformers/all-MiniLM-L6-v2**
- LLM: **Ollama** (default: `llama3.2:3b`)
- Storage: **SQLite** (`rag.db`), local uploads folder

## Prerequisites
- .NET 8 SDK
- Python 3
- Ollama

## Quick Start (Recommended)
From repo root:

### 1) Start everything
```bash
./run.sh

